Com certeza\! Adicionar uma nota sobre a personaliza√ß√£o dos nomes das vari√°veis √© uma √≥tima ideia para tornar o README ainda mais completo e √∫til.

Incorporei essa instru√ß√£o na se√ß√£o de configura√ß√£o das vari√°veis de ambiente. Aqui est√° o README atualizado:

-----

# üöÄ Projeto RAG Manu

Bem-vindo ao **RAG Manu**\! Este √© um sistema flex√≠vel de **Retrieval-Augmented Generation (RAG)** projetado para responder perguntas com base em uma base de conhecimento privada. A arquitetura √© modular, permitindo que voc√™ troque facilmente os componentes principais, como o LLM, o modelo de embedding e o banco de dados vetorial.

## üèõÔ∏è Arquitetura e Componentes Essenciais

Um sistema RAG funciona combinando o poder de um modelo de linguagem (LLM) com a efici√™ncia de uma busca de informa√ß√µes em tempo real. O fluxo b√°sico √©:

`[Seus Documentos] -> [Processamento e Divis√£o] -> [Modelo de Embedding] -> [Banco de Dados Vetorial] -> [Busca por Similaridade] -> [Contexto + Pergunta] -> [LLM] -> [Resposta]`

Este projeto requer a configura√ß√£o de tr√™s componentes principais:

1.  **Modelo de Linguagem (LLM)**: O "c√©rebro" que gera as respostas.

      * **Exemplo Utilizado:** `Azure OpenAI (GPT-4, etc.)`
      * **Alternativas:** OpenAI (API padr√£o), Google Gemini, Anthropic Claude, modelos open-source via Hugging Face.

2.  **Modelo de Embedding**: Respons√°vel por converter texto em vetores num√©ricos para a busca por similaridade.

      * **Exemplo Utilizado:** `Azure OpenAI (text-embedding-3-large)`
      * **Alternativas:** OpenAI (API padr√£o), modelos da Hugging Face (como `sentence-transformers`), etc.

3.  **Banco de Dados Vetorial (Vector Store)**: Onde os vetores dos seus documentos s√£o armazenados e consultados.

      * **Exemplo Utilizado:** `Pinecone`
      * **Alternativas:** ChromaDB, FAISS, Weaviate, etc.

-----

## üìã Pr√©-requisitos

  * Python 3.8+
  * Git
  * Credenciais de API para um **provedor de LLM e Embedding** (ex: Azure OpenAI, OpenAI, etc.)
  * Credenciais de API para um **servi√ßo de Vector Store** (ex: Pinecone)

-----

## ‚öôÔ∏è Configura√ß√£o do Ambiente

#### 1. Clone o reposit√≥rio

```bash
git clone <url-do-repositorio>
cd proj_rag_manu
```

#### 2\. Crie e ative o ambiente virtual

```bash
# Crie o ambiente
python -m venv .venv

# Ative o ambiente
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

#### 3\. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

#### 4\. Configure as vari√°veis de ambiente

Esta etapa √© crucial para conectar o projeto aos servi√ßos externos.

##### a) Copie o arquivo de exemplo

Primeiro, copie o arquivo de exemplo para criar seu pr√≥prio arquivo de configura√ß√£o local:

```bash
cp .env.example .env
```

##### b) Edite o arquivo `.env` com suas credenciais

Abaixo est√° a configura√ß√£o para a implementa√ß√£o de exemplo (Azure + Pinecone).

**Banco de Dados Vetorial (Exemplo: Pinecone)**

```env
# Suas credenciais do Pinecone
PINECONE_API_KEY="SUA_CHAVE_DE_API_DO_PINECONE"
PINECONE_INDEX_NAME="NOME_DO_SEU_INDEX_NO_PINECONE"
```

**LLM e Embedding (Exemplo: Azure OpenAI)**
Para obter estas credenciais, acesse seu recurso do **Azure OpenAI Studio**.

```env
# Endpoint do seu servi√ßo Azure OpenAI
AZURE_OPENAI_ENDPOINT="https://SEU-RECURSO.openai.azure.com/"

# Chave de API do seu servi√ßo Azure OpenAI
AZURE_OPENAI_API_KEY="SUA_CHAVE_DE_API_DO_AZURE"

# Vers√£o da API que voc√™ est√° usando (encontrada no portal Azure)
OPENAI_API_VERSION="2024-02-01"

# Nome do "deployment" do seu modelo de LLM (ex: gpt-4)
AZURE_OPENAI_DEPLOYMENT="NOME_DO_DEPLOYMENT_DO_LLM"

# Nome do "deployment" do seu modelo de embedding (ex: text-embedding-3-large)
AZURE_OPENAI_DEPLOYMENT_NAME="NOME_DO_DEPLOYMENT_DO_EMBEDDING"
```

##### c) Personalizando os Nomes das Vari√°veis (Opcional)

Os nomes de vari√°veis no arquivo `.env.example` s√£o um padr√£o sugerido. Se voc√™ prefere usar uma conven√ß√£o de nomenclatura diferente (por exemplo, para evitar conflitos com outros projetos ou seguir um padr√£o de equipe), sinta-se √† vontade para alter√°-los.

**Importante:** Qualquer altera√ß√£o feita no nome da vari√°vel dentro do arquivo `.env` **deve ser refletida no c√≥digo** onde ela √© lida (`os.getenv(...)`).

**Exemplo de personaliza√ß√£o:**

1.  **No arquivo `.env`, voc√™ muda de:**

    ```env
    AZURE_OPENAI_API_KEY="sua-chave-secreta"
    ```

    **Para:**

    ```env
    RAG_MANU_AZURE_API_KEY="sua-chave-secreta"
    ```

2.  **No c√≥digo Python (ex: `back-end/config.py`), voc√™ deve atualizar a chamada correspondente:**
    **De:**

    ```python
    api_key=os.getenv("AZURE_OPENAI_API_KEY")
    ```

    **Para:**

    ```python
    api_key=os.getenv("RAG_MANU_AZURE_API_KEY")
    ```

-----

### üí° Adaptando para Outros Provedores

Para usar outros servi√ßos (como a API padr√£o da OpenAI), voc√™ precisar√°:

1.  **Alterar as vari√°veis de ambiente** no arquivo `.env`.
2.  **Modificar o c√≥digo** (principalmente no arquivo `back-end/config.py`) para instanciar a classe correta.

-----

## üöÄ Como Executar

Ap√≥s configurar o ambiente e as vari√°veis, execute o pipeline principal:

```bash
python back-end/main.py
```

Isso iniciar√° o processo de leitura dos documentos, gera√ß√£o de embeddings e armazenamento no seu Vector Store.